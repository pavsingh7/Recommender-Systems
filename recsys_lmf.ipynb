{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latent Matrix Factorization\n",
    "\n",
    "Latent matrix factorization (LMF) is a popular **technique in recommender systems for predicting user-item preferences**. \n",
    "\n",
    "    The basic idea: factorize the user-item preference matrix into two lower-dimensional matrices, such that their product approximates the original matrix. These lower-dimensional matrices represent latent factors (hidden variables) that capture the underlying relationships between users and items.\n",
    "\n",
    "In LMF, the user-item preference matrix is factorized into two matrices: the user-factor matrix and the item-factor matrix. \n",
    "\n",
    "- The **user-factor matrix** represents the preferences of users for different latent factors, while \n",
    "\n",
    "- The **item-factor matrix** represents the latent factors of the items. \n",
    "\n",
    "The **dot product of these two matrices approximates the original user-item preference matrix**.\n",
    "\n",
    "In order to make predictions, the dot product of a user's factor vector and an item's factor vector gives an estimate of the user's preference for that item. The predicted preferences can be compared to the actual preferences to determine the accuracy of the model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Brief History & Background\n",
    "\n",
    "LMF was motivated by the goal of reducing the dimensionality of the user-item preferences matrix, making it easier to model and make recommendations. LMF quickly became popular in the field of recommender systems due to its simplicity and ability to handle large-scale, sparse user-item preference data.\n",
    "\n",
    "\n",
    "## Applications\n",
    "LMF is widely used in various industries such as e-commerce, entertainment, and advertising to make recommendations to users. For example, in e-commerce, LMF can be used to recommend products to users based on their past purchases, searches, and ratings. In the entertainment industry, LMF can be used to recommend movies, TV shows, and music to users based on their past viewing and listening behaviors. In the advertising industry, LMF can be used to target ads to users based on their interests and preferences"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Generating Latent Matrices\n",
    "\n",
    "The user-item preference matrix in latent matrix factorization (LMF) is factorized into two lower-dimensional matrices -  user and item latent matrices. These matrices capture the underlying relationships between users and items and represent them in a lower-dimensional space. The factorization is performed using matrix factorization techniques such as **singular value decomposition (SVD)** or **non-negative matrix factorization (NMF)**.\n",
    "\n",
    "Here is a general outline of the factorization process:\n",
    "\n",
    "1. Initialize the user and item latent matrices with random values.\n",
    "2. Multiply the user and item latent matrices to obtain a reconstructed matrix that approximates the original user-item preference matrix.\n",
    "3. Calculate the error between the original user-item preference matrix and the reconstructed matrix.\n",
    "4. Update the user and item latent matrices to reduce the error.\n",
    "5. Repeat steps 2 to 4 until the error reaches a minimum or a stopping criterion is met.\n",
    "\n",
    "The final user and item latent matrices can be used to make recommendations to users. For example, the predicted preference of a user for an item can be calculated by taking the dot product of the user and item latent vectors corresponding to that user and item. The items with the highest predicted preferences can be recommended to the user.\n",
    "\n",
    "## Example Problem & Process\n",
    "\n",
    "Suppose you have a 15 by 20 user-item ratings matrix. We want to apply LMF  on this. We follow the below steps:\n",
    "\n",
    "1. **Preprocessing**: You may want to normalize the ratings by subtracting the mean and dividing by the standard deviation to ensure that the ratings are on a comparable scale. You can also remove any missing values or sparse entries in the matrix.\n",
    "\n",
    "2. **Factorization**: Decide on the number of latent factors you want to use for the factorization. This is a hyperparameter that you need to tune. You can use a matrix factorization technique such as singular value decomposition (SVD) or non-negative matrix factorization (NMF) to factorize the user-item ratings matrix into two matrices: a user latent matrix and an item latent matrix.\n",
    "\n",
    "3. **Training**: Train the LMF model using the factorized matrices and the user-item ratings data. The goal is to minimize the reconstruction error between the original user-item ratings matrix and the product of the user and item latent matrices. You can use optimization techniques such as gradient descent or alternating least squares to update the user and item latent matrices.\n",
    "\n",
    "4. **Evaluation**: Evaluate the performance of the LMF model on a separate validation or test dataset. Common evaluation metrics include root mean squared error (RMSE) and mean average precision (MAP). You can also use ranking metrics such as precision, recall, and F1-score to evaluate the quality of top-N recommendations.\n",
    "\n",
    "5. **Hyperparameter Tuning**: Repeat steps 2 to 4 with different numbers of latent factors and different regularization techniques to find the best model that gives the lowest reconstruction error. You can use techniques such as cross-validation or grid search to find the optimal hyper-parameters.\n",
    "\n",
    "6. **Making Recommendations**: Once you have a well-trained LMF model, you can use it to make recommendations to users. For example, you can calculate the dot product of the user and item latent vectors corresponding to a user and an item to predict the user's preference for that item. The items with the highest predicted preferences can be recommended to the user.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Regularization & Overfitting\n",
    "\n",
    "LMF can also be regularized to prevent overfitting by adding penalty terms to the objective function. Regularization can be used to encourage the model to find a low-rank approximation to the preference matrix, which helps prevent overfitting to noise in the data.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Bias Term\n",
    "\n",
    "In latent factor models like matrix factorization, adding bias terms helps to capture and correct for any biases in the data. This is important because it can improve the accuracy of the model. Bias terms can capture effects such as popularity of movies, which would mean that some movies have higher ratings just because they are more popular, regardless of their actual quality. By adding these bias terms, the model can correct for these effects and produce more accurate recommendations."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Summary\n",
    "\n",
    "In conclusion, LMF works by factorizing the user-item preference matrix into two matrices that represent latent factors, which are used to make predictions about user-item preferences. LMF can be regularized to prevent overfitting, making it a useful technique for building recommender systems. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
